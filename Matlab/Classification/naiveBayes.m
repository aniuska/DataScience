%% Naive Bayes model for binomial classification
%  Dataset: Student performance on Portugues and Maths. Data set can be downloand at https://archive.ics.uci.edu/ml/datasets/Student+Performance
%  Data Description: 29 out of 36 features where used for the classification
%      - Features: 16 categorical and 13 numeric - descrete 
%      - Labels(desired target): Two classes {"Pass","Fail"}
% 
%  Model parameters used: 
%       - Distribution names: features values distribution
%             a) Assumption known distribution for features - normal, parametric (mu,sigma) representation of 
%                probability distrubution (default by the system)
%             b) Assumption unknown distributionfor features - Kernel, nonparametric representation 
%                of the probability density function(smoothing density estimate)
%       - Prior: prior class probability distribution
%             a) the relative frequency distribution of the classes in the data set (default by the system)
%             b) sets all class probabilities equal (uniform).
%       - Posterior: logarithmic transformations
%  Strategy: 
%       - 10 folds cross validation to validate generalization
%       - Raw data is used 
%       - Run script twice (2 rounds) changing parameters for comparation
%           -- 1st round: parameters choosen by the system
%               * Distribution names: 'mvnm' for categorical features and 'normal'
%                 for numeric feaures
%               * Prior: 'empirical' - relative frequency distribution of the classes in the data set
%           -- 2nd round: parameters given explicitly
%               * Distribution names: 'mvnm' for categorical features and 'kernel'
%                 for numeric feaures using 'epanechnikov','normal' as
%                 smoothers
%               * Prior: 'uniform', 'empirical'
%               * Posterior: 'ScoreTransform' - 'logit','doublelogit'
%
% The software treats the predictors as independent given a class, and, by default, fits them using 
% normal distributions.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
clear; % make sure previously defined variables are erased.
opengl('save','software');

%% Import Existing Data
% In this example, the data is loaded from .csv file to a MATLAB table
% Autogenerated code for reading dataset
%Reading all data
%file = 'student-por.csv';
file = 'student-mat.csv';
student1 = LoadStudentData_NB(file,2,650);

% Selecting Predictors(Features) for Analysis
student = student1(:,[1:4 6:29 end]); 
%Predictors(Features) names
names = student.Properties.VariableNames;

% Convert all the categorical variables into nominal arrays
[nrows, ncols] = size(student);
category = false(1,ncols);
for i = 1:ncols
    if isa(student.(names{i}),'categorical') || isa(student.(names{i}),'nominal')
        category(i) = true;
        student.(names{i}) = nominal(student.(names{i}));
    end
end

% Set the random number seed to make the results repeatable in this script
rng('default');
%% Diveide the Data on Response(labels) and Predictors(features)
% Two classes: Fail(0) and Pass(1)

% Response vector - labels
Y = student.Response;
%disp('Labels');
%tabulate(Y);

% Predictor (features) matrix
n=size(student,2);
X = student(:,1:n-1);

rng(1); % For reproducibility
%%Naive Bayes Model - Training the model using Cross validation
%% Cross Validation - 10 folds
K = 10; %Number of folds
cv = cvpartition(height(student),'kfold',K); %Defining partitions for cross validation

% Variables Initialisation
C_glm = zeros(2,2); %confusion matrix
mse = zeros(K,1);   %mean squeared error vector
isGenRate = zeros(K,1);  %misclassification rate vector
post = zeros(K,1); %posterior vector
roc = struct('X',{},'Y',{},'T',{},'AUC',0.0,'OPTROCPT',{}); %ROC matrix structure
avgAcc = 0; %Aveage accuracy
Acc = zeros(K,1); %accuracy vector

%Used on 2nd round
distNames = {'mvmn' 'mvmn' 'kernel' 'mvmn' 'mvmn' 'kernel' 'kernel' 'mvmn' 'mvmn'  'mvmn' 'kernel' 'kernel' 'kernel' 'mvmn' 'mvmn' 'mvmn' 'mvmn' 'mvmn' 'mvmn' 'mvmn' 'mvmn' 'kernel' 'kernel' 'kernel' 'kernel' 'kernel' 'kernel' 'kernel'}; 
Kernel={'epanechnikov','normal'}; %Kernel smoother types

fprintf('----------------------------\n');
fprintf('- Naive Bayes Training model -\n');
fprintf('----------------------------\n\n');
fprintf('Dataset: %s\n',file);

tic; %stopwatch timer to measure performance 10-fold cross validation
for k=1:K
    % training/testing indices for the k fold
    trainIdx = cv.training(k);
    testIdx = cv.test(k);
    
    %Training Set
    X_train = X(trainIdx,:);
    Y_train = Y(trainIdx);
    
    %Test Set
    X_test = X(testIdx,:);
    Y_test = Y(testIdx);
    
    fprintf('\n \n ---- Cross-Validation fold %d -----\n',k);
    
    tStart = tic; %stopwatch timer to measure performance for this fold
    
    % Train the classifier Naive Bayes - Fitting a naive Bayes classifier
    %1st round
    glm = fitcnb(X_train,Y_train); %1 
    %glm = fitcnb(X_train,Y_train,'ScoreTransform' , 'logit');
    %glm = fitcnb(X_train,Y_train,'ScoreTransform' , 'doublelogit');
    %glm = fitcnb(X_train,Y_train,'ScoreTransform' , 'ismax');
    %glm = fitcnb(X_train,Y_train,'ScoreTransform' , 'invlogit');
    
    %2nd round - empirical prior (default) determines class probabilities from class frequencies in Y
    %glm = fitcnb(X_train,Y_train,'Distribution',distNames,'ScoreTransform','logit'); %2
    %glm =fitcnb(X_train,Y_train,'Distribution',distNames,'Kernel','normal'); %3
    %glm = fitcnb(X_train,Y_train,'Distribution',distNames,'Kernel','epanechnikov'); %4
    
    %2nd round - uniform prior
    %glm =fitcnb(X_train,Y_train,'Distribution',distNames,'Prior','uniform'); %5
    %glm = fitcnb(X_train,Y_train,'Distribution',distNames,'Prior','uniform','Kernel','normal');
    %glm = fitcnb(X_train,Y_train,'Distribution',distNames,'Prior','uniform','Kernel','epanechnikov');                 

    % Make a prediction for the test set 
    Y_glm = glm.predict(X_test);
    %Y_glm = round(Y_glm);
   
    %Metric: 1) Accuracy
    %Estimating the misclassification error - misclassification rate is isGenRate value in percent
    %Assess the in-sample performance of Mdl by estimating the misclassification error.
    %Fraction of misclassified data, weighted by w
    %Proportion of observations that the classifier misclassifies.
    %The expected loss
    isGenRate(k) = resubLoss(glm,'LossFun','ClassifErr'); 
        
    %idx = randsample(sum(testIdx),10);
    %Compute the posterior probabilities (scores) and cost for Naive Bayes 
    [predictLabels1,Posterior,MisclassCost] = predict(glm,X_test);
    rng(1); % For reproducibility
  
    idx = randsample(size(X_test,1),10);
    glm.ClassNames;
    T2=table(Y_test(idx),predictLabels1(idx),Posterior(idx,:),'VariableNames',{'TrueLabel','PredictedLabel','PosteriorProbability'});
    missClassificationCost = MisclassCost(idx,:);
    
    %Compute the confusion matrix
    [ConfusionMat1,labels] = confusionmat(Y_test,predictLabels1);
    T=table(Y_test,predictLabels1,'VariableNames',{'TrueLabel','PredictedLabel'});
    
    TP = ConfusionMat1(1,1); %True positive: correctly clasified as Pass
    TN = ConfusionMat1(2,2); %True negative: correctly rejected as Fail
    FP = ConfusionMat1(1,2); %False positive: Incorrectly classified as Pass
    FN = ConfusionMat1(2,1); %False negative: Incorretcly recjeted as Fail
        
    Acc(k) = Acc(k) + (TP + TN)./(TP + TN + FP + FN);
    avgAcc = avgAcc + (Acc(k)/K);
    
    fprintf('\nTest Accuracy: %f\n Elapsed time: %s\nMisclassification rate: %d %% \n',Acc(k),toc(tStart),round(isGenRate(k)*100));
    %disp(T);
        
    %Metric: 2) Mean squared error
    %Describe the performance of a classifier - assessesing the quality of an estimator 
    Y_b = double(categorical(Y_test,'Ordinal',true));
    Yes_b = double(categorical(Y_glm,'Ordinal',true));
    mse(k) = mean((Y_b - Yes_b).^2);
    
    %[label,Posterior,MisclassCost] = resubPredict(glm);
    
    %Metric 3)ROC curve
    %Compute the standard ROC curve using the scores (posteriors) from the Naive Bayes classification.
    %to evaluate classifier performance on test data after you train the classifier.
    %In this case, perfcurve returns X, Y, and T (threshold) values for all scores 
    %and computes pointwise confidence bounds for X and Y using threshold averaging
    %perfcurve(True class labels, Posterior, Positive class value)
    %[Xnb,Ynb,Tnb,AUCnb] = perfcurve(glm.Y,Posterior(:,2),'Pass');
    [Xnb,Ynb,Tnb,AUCnb,OPTROCPT] = perfcurve(Y_test,Posterior(:,2),'Pass');
    roc(k).X=Xnb;
    roc(k).Y=Ynb;
    roc(k).T=Tnb;
    roc(k).AUC=AUCnb;
    roc(k).OPTROCPT=OPTROCPT;
end

%Average root-mean-square-error to give a sense of avrg of the Predicted values error
avrg_rmse = mean(sqrt(mse)); 

%Average elapsed time performance for 10-fold cross validation
averageTime = toc/K; 

%Misclassification average
avrgMissClass = mean(isGenRate);

fprintf('\nAverage Root Mean square error: %f\n Average Elapsed time: %f \n',avrg_rmse,averageTime);
fprintf('\nAverage Missclasification: %d %%\n Average Accuracy %f \n',round(avrgMissClass*100),avgAcc);

%Plot the ROC curves on the same graph.
figure;
lv = repmat({''}, K, 1);
pmarker = {'o','*','x','s','+','d','v','p','.','h'};
idxM=0;
mx = 0.0;
for k=1:K 
  pl = plot(roc(k).X,roc(k).Y);
  pl.Marker=pmarker{k};
  lv{k}=strcat('k = ',int2str(k));
  %Selecting the highest AUC - for presentation plots 
  if roc(k).AUC > mx 
      idxM = k;
      mx = roc(k).AUC;
  end
  hold on;
end
legend(lv);
xlabel('False positive rate');
ylabel('True positive rate');
title('ROC curves on Test set for Naive Bayes Classification');
hold off

%For presentation images
%Save into a file best ROC performance for each Model
%Get the Higher AUC and save X and Y generated by perfcurve
%[mx,midx] = max(roc(:).AUC); %didn't work properly
%S=load('rocPor_test.mat');
%mmodel5_X = roc(idxM).X;
%mmodel5_Y = roc(idxM).Y;
%save('rocPor_test.mat', 'mmodel5_X','mmodel5_Y','-append'); %

figure;
for k=1:K 
  pl=plot(roc(k).OPTROCPT(1),roc(k).OPTROCPT(2));
  pl.Marker=pmarker{k};
  lv{k}=strcat('k = ',int2str(k));
  hold on;
end
legend(lv);
xlabel('False positive rate');
ylabel('True positive rate');
title('Optimal operating point of the ROC curves on Test set for Naive Bayes Classification');
hold off
%% References
% [Moro et al., 2011] S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: 
% An Application of the CRISP-DM Methodology. In P. Novais et al. (Eds.), Proceedings of the European 
% Simulation and Modelling Conference - ESM'2011, pp. 117-121, Guimar√£es, Portugal, October, 2011. EUROSIS.